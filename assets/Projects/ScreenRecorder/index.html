<!DOCTYPE html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title></title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="">
    <style>
        .mainMenuSettings {
            position: absolute;
            top: 0;
            right: 50px;
        }
        
        canvas {
            border: 1px solid green;
        }
    </style>
</head>

<body>
    <p id="warning">
        Enable chrome://flags/#enable-experimental-web-platform-features
    </p>
    <div class="left">
        <h2>Preview</h2>
        <video id="camElement" autoplay muted></video>
        <video id="videoElement" autoplay muted></video>
    </div>
    <div class="right">
        <h2>Recording</h2>
        <canvas width="960" height="540">
            
        </canvas>
    </div>
    <div>

    </div>
    <div class="mainMenuSettings">
        <div id="captureVideoButton" class="button">
            <button>Capture Device</button>
        </div>
        <input type="checkbox" id="audioToggle" />
        <label for="audioToggle">Capture Audio from Desktop</label><br>
        <input type="checkbox" id="micAudioToggle" />
        <label for="micAudioToggle">Capture Audio from Microphone</label><br>
        <div id="startVideoButton" class="button">
            <button>Start Recording</button>
        </div>
        <div id="stopVideoButton" class="button">
            <button>Stop Recording</button>
        </div>
        <h2>Result</h2>
        <a id="download" href="#" style="display: none;">Download</a>
        <video id="resultRecording" width="300" height="150" controls></video>
    </div>

    <script>
        // init
        let warningElement = document.getElementById('warning');
        if ('getDisplayMedia' in navigator.mediaDevices) warningElement.style.display = 'none';

        const camElement = document.getElementById('camElement');
        camElement.width = screen.width / 6;
        camElement.height = screen.height / 6;

        const videoElement = document.getElementById('videoElement');
        videoElement.width = screen.width / 6;
        videoElement.height = screen.height / 6;

        const audioToggle = document.getElementById('audioToggle');
        const micAudioToggle = document.getElementById('micAudioToggle');

        const canvas = document.querySelector("canvas");
        canvas.width = screen.width / 2;
        canvas.height = screen.height / 2;
        const ctx = canvas.getContext('2d');


        const captureVideoButton = document.getElementById("captureVideoButton");
        const startVideoButton = document.getElementById("startVideoButton");
        const stopVideoButton = document.getElementById("stopVideoButton");
        const download = document.getElementById('download');
        const resultRecording = document.getElementById('resultRecording');

        // methods
        let voiceStream;
        let webcamStream;
        let desktopStream;

        // recording

        let rec;
        var requestAnimationStream;
        var streamCam;
        var streamDesktop;
        var audioDesktop;
        var cam;


        const mergeAudioStreams = (desktopStream, voiceStream) => {
            const context = new AudioContext();
            const destination = context.createMediaStreamDestination();
            let hasDesktop = false;
            let hasVoice = false;
            if (desktopStream && desktopStream.getAudioTracks().length > 0) {
                // If you don't want to share Audio from the desktop it should still work with just the voice.
                const source1 = context.createMediaStreamSource(desktopStream);
                const desktopGain = context.createGain();
                desktopGain.gain.value = 0.7;
                source1.connect(desktopGain).connect(destination);
                hasDesktop = true;
            }

            if (voiceStream && voiceStream.getAudioTracks().length > 0) {
                const source2 = context.createMediaStreamSource(voiceStream);
                const voiceGain = context.createGain();
                voiceGain.gain.value = 0.7;
                source2.connect(voiceGain).connect(destination);
                hasVoice = true;
            }

            return (hasDesktop || hasVoice) ? destination.stream.getAudioTracks() : [];
        };


        captureVideoButton.onclick = async() => {
            // download.style.display = 'none';
            const audio = audioToggle.checked || false;
            const mic = micAudioToggle.checked || false;
            cam = confirm("use camera as capture device too?");


            desktopStream = await navigator.mediaDevices.getDisplayMedia({
                video: true,
                audio: audio,
            });

            if (cam === true) {
                webcamStream = await navigator.mediaDevices.getUserMedia({
                    video: true,
                    audio: false
                });
            }

            if (mic === true) {
                voiceStream = await navigator.mediaDevices.getUserMedia({
                    video: false,
                    audio: mic
                });
            }

            const desktoptracks = [
                ...desktopStream.getVideoTracks(),
            ];
            const desktopAudiotracks = [
                ...voiceStream.getAudioTracks(),
            ];
            console.log(audio)
            console.log('Desktop add to stream', desktoptracks);
            streamDesktop = new MediaStream(desktoptracks);
            console.log('streamDesktop', streamDesktop);
            console.log("INPUT", "STREAM", desktoptracks)
            console.log("INPUT", "STREAM", desktopAudiotracks)
            audioDesktop = new MediaStream(desktopAudiotracks);
            console.log('audioDesktop', audioDesktop);
            videoElement.srcObject = streamDesktop;
            videoElement.muted = true;

            if (cam === true) {
                const camtracks = [
                    ...webcamStream.getVideoTracks(),
                ];
                console.log('Cam add to stream', camtracks);
                streamCam = new MediaStream(camtracks);
                console.log('streamCam', streamCam);
                camElement.srcObject = streamCam;
                camElement.muted = true;
            }
        }


        var streamCanvas;
        videoElement.onplay = () => {

            // desktop recording settings
            videoElement.scale = Math.min(
                canvas.width / videoElement.videoWidth,
                canvas.height / videoElement.videoHeight);
            var scale = videoElement.scale;
            var vidH = videoElement.videoHeight;
            var vidW = videoElement.videoWidth;
            var top = canvas.height / 2 - (vidH / 2) * scale;
            var left = canvas.width / 2 - (vidW / 2) * scale;

            // cam recording settings
            // source cam
            var sourceStartX = 150,
                sourceStartY = 100,
                sizeSourceWidth = 320,
                sizeSourceHeight = 300;
            // destination canvas
            var destinationSizeX = 150,
                destinationSizeY = 150,
                destinationStartX = canvas.width - destinationSizeX, // right side of the screen
                destinationStartY = canvas.height - destinationSizeY;



            blobs = [];
            streamCanvas = canvas.captureStream(); // frames per second
            const context = new AudioContext();
            const destination = context.createMediaStreamDestination();
            const source1 = context.createMediaStreamSource(desktopAudiotracks);
            const desktopGain = context.createGain();
            desktopGain.gain.value = 0.7;
            source1.connect(desktopGain).connect(destination);
            streamCanvas.addTrack(source1);



            rec = new MediaRecorder(streamCanvas, {
                mimeType: 'video/webm; codecs=vp8,opus'
            });

            rec.ondataavailable = (e) => blobs.push(e.data);
            rec.onstop = async() => {
                //blobs.push(MediaRecorder.requestData());
                blob = new Blob(blobs, {
                    type: 'video/webm'
                });
                let url = window.URL.createObjectURL(blob);
                download.href = url;
                download.download = 'test.webm';
                download.style.display = 'block';
                resultRecording.src = URL.createObjectURL(blob);
            };



            function step() {
                ctx.drawImage(videoElement, left, top, vidW * scale, vidH * scale);
                if (cam === true) {
                    ctx.drawImage(camElement, sourceStartX, sourceStartY, sizeSourceWidth, sizeSourceHeight, destinationStartX, destinationStartY, destinationSizeX, destinationSizeY);
                }
                // ctx.drawImage(videoElement, 0, 0);
                requestAnimationStream = requestAnimationFrame(step)
            }
            requestAnimationStream = requestAnimationFrame(step);
        }

        startVideoButton.onclick = () => {
            console.log("Start to recording...")
            rec.start();
        };
        stopVideoButton.onclick = () => {
            console.log("Stop to recording...")
            rec.stop();
            streamCanvas.getTracks().forEach(s => s.stop())
            streamDesktop.getTracks().forEach(s => s.stop())
            if (cam === true) {
                streamCam.getTracks().forEach(s => s.stop())
            }
            videoElement.srcObject = null;
            camElement.srcObject = null;
            streamCanvas = null;
            streamDesktop = null;
            streamCam = null;
            window.cancelAnimationFrame(requestAnimationStream);
            ctx.fillStyle = "white";
            ctx.fillRect(0, 0, canvas.width, canvas.height);
        };
    </script>
</body>

</html>